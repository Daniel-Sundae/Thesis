\chapter{Hard problems}\label{sec:hard_problems}

In this section, we assume every vector is a column vector and we denote a matrix $\mathbf{A}$ with boldface. By $\mathbf{A} \in \mathbb{F}^{n \times m}$ we mean $\mathbf{A}$ is a $n \times m$ matrix with entries in $\mathbb{F}$. Consider a basis $\mathbf{B} = \{b_1, \dots, b_k\}$. A lattice with basis $\mathbf{B}$ is defined $L(\mathbf{B}) \stackrel{\mathrm{def}}{=} \{ \sum_{i=1}^k a_i b_i \; \mid a_i \in \mathbb{Z}\}$. 

\section{LWE}\label{subsec:LWE}
In 2005, Oded Regev introduced \cite{Reg05-LWE} a natural problem; solve a system of modular noisy linear equations. The problem is called learning with errors (LWE) and in 2012, a ring based version called ring-LWE (RLWE) was introduced \cite{RLWE}. Despite being easy to state, the LWE problem turns out to be hard even on average instances. For certain parameter choices, the LWE problem is reducible to extensively studied hard lattice based problems (e.g., GapSVP, SIVP) whereas RLWE is reducible to hard problems on ideal lattices (e.g., ideal-SVP, NTRU). Hardness of these problems are mostly outside the scope of this thesis but we will revisit some basics when arguing security in Chapter \ref{ch:implementation}; we refer the curious reader to \cite{Reg05-LWE, LWE-classical-reduction, LWE-hardness, RLWE} for more details on hardness results and \cite{Pei16-decade} for a good rundown on hard lattice based problems. Today, essentially all homomorphic encryption schemes are based on LWE and RLWE.

The parameters for $\operatorname{LWE}$ are the integers $n = n(\lambda)$ for the dimension, $q = q(n)$ for the global modulus, $m$ for number of samples and a discrete error distribution measure $\chi = \chi(\lambda)$ over $\mathbb{Z}$.

Consider the space of $n \times m$ matrices $\mathbb{Z}_q^{n \times m}$ with uniform distribution, space of secrets $\mathbb{Z}_q^{n}$ with uniform distribution\footnote{The space of secrets can have distribution $\chi^n$ without loss of hardness. See \cite{Applebaum}.}, space of errors $\mathbb{Z}^{m}$ with discrete distribution $\chi^m$ and the random variable $A_{n, q, \chi, m}$ defined on the direct product as follows
\begin{equation*}
\begin{aligned}
    A_{n, q, \chi, m} \colon \mathbb{Z}_q^{n \times m} \times \mathbb{Z}_q^n \times \mathbb{Z}^m &\to \mathbb{Z}_q^{n \times m} \times \mathbb{Z}_q^m \cong \mathbb{Z}_q^{(n+1) \times m}\\
    (\mathbf{A},s,e) &\mapsto (\mathbf{A}, b^T \stackrel{\mathrm{def}}{=} s^T\mathbf{A}+e^T \pmod q) = \left[\begin{array}{c} \mathbf{A} \\ b^T \end{array}\right]
\end{aligned}
\end{equation*}
\begin{definition}[LWE distribution]
    The learning with errors distribution is defined as the distribution of $A_{n, q, \chi, m}$
    \begin{equation*}
    \begin{aligned}
        \operatorname{LWE}_{n, q, \chi, m} \stackrel{\mathrm{def}}{=} \mathcal{L}(A_{n, q, \chi, m})
    \end{aligned}
    \end{equation*}
\end{definition}

In words, sample a $n \times m$ matrix $\mathbf{A}$ with entries in $\mathbb{Z}_q$ at random, choose a uniformly random secret $s \leftarrow \mathbb{Z}_q^n$ and let $e$ consist of $m$ independent errors from the discrete distribution $\chi$. Calculate $b^T$ (i.e, $s^T\mathbf{A}+e^T \pmod q$) and output the pair $(\mathbf{A},b^T)$. The $\operatorname{LWE}$ distribution specifies the probability of sampling each pair.

There are two versions of the $\operatorname{LWE}$ problem; search-$\operatorname{LWE}$ and decision-$\operatorname{LWE}$.
Informally, take a sample $x \leftarrow \operatorname{LWE}_{n, q, \chi, m}$ and consider the last row. The decision version is to decide whether the last row is a linear combination of the previous $n$ rows or if it is uniformly random and the search version is to find the explicit linear combination assuming it exists.

\begin{definition}[decision-$\operatorname{LWE}$ problem]
    Let $\mathcal{U}_n$ be the uniform distribution on $\mathbb{Z}_q^{(n+1) \times m}$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
        |\operatorname{Pr}[A(\mathcal{U}_n) = 1] - \operatorname{Pr}[A(\operatorname{LWE_{n,q,\chi,m}}) = 1]| > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The decision-LWE hardness assumption is that $\mathcal{U}_n$ and $\operatorname{LWE}_{n,q,\chi,m}$ are computationally indistinguishable (i.e., $\operatorname{LWE}_{n,q,\chi,m}$ is pseudorandom).
\begin{definition}[search-$\operatorname{LWE}$ problem]
    Let $x = (\mathbf{A}, b^T) \leftarrow \operatorname{LWE}_{n,q,\chi,m}$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
            \operatorname{Pr}[A(x) = s] > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The search-LWE hardness assumption is that $\operatorname{Pr}[A(x) = s] = \operatorname{negl}(n)$.
There exists a reduction from search-$\operatorname{LWE}$ to decision-$\operatorname{LWE}$ for $q = \operatorname{poly}(n)$, meaning they are equivalently hard \cite{LWE-hardness}. We write $\operatorname{LWE}$ assumption to refer to hardness of both the search and decision versions. 

For the sake of concreteness, typical parameters are $n = \Theta(\lambda), q = \operatorname{poly}(n)$, $m = \omega(n)$, $\chi = \textrm{D}_{\mathbb{Z}, \sqrt{n}, \vec{0}}(\vec{x})$ for bound $\beta = 3\sigma$. Remember that this $\beta$ implies this distribution is subgaussian with parameter $3s = 3\sqrt{n}$, which is exactly the error parameter we use for the subgaussian distribution in our implementation, see Section \ref{sec:parameters}. The $\operatorname{LWE}$ problem can be thought of as the matrix $\mathbf{A}$ acting on the secret $s$ as a linear transformation, generating the vector $s^T\mathbf{A}$ in the rowspace of $\mathbf{A}$ as the 'true' solution. The problem is then to find $s^T\mathbf{A}$ given a $b$ in the $m$ dimensional ball with radius specified by error bound, centered at $s^T\mathbf{A}$.\footnote{The knowledgable reader may see the resemblence to the bounded-distance decoding (BDD) problem}. In Chapter \ref{ch:implementation}, we show how to base a cryptosystem on the LWE hardness assumption.

\section{RLWE}
The LWE problem is conceptually easy to understand but suffers from expensive overhead. Each element in $b$ is a perturbed linear combination of the secret $s$ and the corresponding column in $\mathbf{A}$, resulting in $O(n)$ operations. To get $m = n$ samples, the total number of operations is $O(n^2)$. In 2012, a more compact ring based learning with errors problem ($\operatorname{RLWE}$) was introduced by Lyubashevsky, Peikert and Regev in \cite{RLWE}.

The parameters for $\operatorname{RLWE}$ are the integers $n = n(\lambda)$ for the dimension, $q = q(n)$ for the global modulus and a discrete error distribution measure $\chi = \chi(\lambda)$ over $\mathbb{Z}$.

Let the dimension $n = 2^k$ for some natural number $k$ and consider the irreducible polynomial $f(x) = x^n + 1$. Define the polynomial ring $R_q \stackrel{\mathrm{def}}{=} \mathbb{Z}_q[x] /\langle f(x)\rangle$. The ring $R_q$ is viewed as the ring of polynomials with coefficients in $\mathbb{Z}_q$, having degree less than $n$. There is a natural correspondence between elements of $R_q$ and $\mathbb{Z}_q^n$ where each polynomial coefficient corresponds to an element in the vector. Let the error space $R_q'$ be $R_q$ endowed with error distribution $\chi^n$ over the integer coefficients and consider the random variable $A'_{n, q, \chi}$ defined as follows
\begin{equation*}
\begin{aligned}
    A'_{n, q, \chi} \colon R_q \times R_q \times R_q' &\to R_q^2\\
    (a,s,e) &\mapsto (a, b \stackrel{\mathrm{def}}{=} a \cdot s + e \pmod q)
\end{aligned}
\end{equation*}
\begin{definition}[RLWE distribution]
    The learning with errors distribution is defined as the distribution of $A'_{n, q, \chi}$
    \begin{equation*}
    \begin{aligned}
        \operatorname{RLWE}_{n, q, \chi} \stackrel{\mathrm{def}}{=} \mathcal{L}(A'_{n, q, \chi})
    \end{aligned}
    \end{equation*}
\end{definition}
In words, sample a uniformly random polynomial $a \in R_q$, a uniformly random secret $s \in R_q$ and a random error $e \in R_q$ from the discrete distribution $\chi^n$. Calculate $b$ (i.e, $a \cdot s + e \pmod q$) and output the pair $(a,b)$. The $\operatorname{RLWE}$ distribution specifies the probability of sampling each pair.

The decision-$\operatorname{RLWE}$ problem is to distinguish between the $\operatorname{RLWE}$ distribution and the uniform distribution on $R_q^2$ and the search problem is to find the secret $s$ given a sample $(a,b) \leftarrow \operatorname{RLWE}_{n,q,\chi}$.
\begin{definition}[decision-$\operatorname{RLWE}$ problem]
    Let $\mathcal{U}_n$ be the uniform distribution on $R_q^2$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
        |\operatorname{Pr}[A(\mathcal{U}_n) = 1] - \operatorname{Pr}[A(\operatorname{RLWE_{n,q,\chi}}) = 1]| > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The decision-$\operatorname{RLWE}$ hardness assumption is that $\mathcal{U}_n$ and $\operatorname{RLWE}_{n,q,\chi}$ are computationally indistinguishable (i.e., $\operatorname{RLWE}_{n,q,\chi}$ is pseudorandom).
\begin{definition}[search-$\operatorname{RLWE}$ problem]
    Let $x = (a, b) \leftarrow \operatorname{RLWE}_{n,q,\chi}$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
            \operatorname{Pr}[A(x) = s] > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The search-$\operatorname{RLWE}$ hardness assumption is that $\operatorname{Pr}[A(x) = s] = \operatorname{negl}(n)$.

Note that in $\operatorname{LWE}$, the sample size $m$ is embedded as a parameter while in $\operatorname{RLWE}$, adversary generates $m = \operatorname{poly}(\lambda)$ samples from the $\operatorname{RLWE}_{n,q,\chi}$ themselves.

In $\operatorname{LWE}$, the $b$ vector is of size $m$. Each element is calculated by an inner product of the secret $s$ and the corresponding column in $\mathbf{A}$, resulting in $O(n)$ operations. To get $m = n$ samples, the total number of operations is $O(n^2)$. For $\operatorname{RLWE}$, the b vector is a polynomial with $n$ coefficients. By using the fast fourier transform (FFT) algorithm, polynomial multiplication can be calculated in $O(n \log n)$ operations. To get $n$ samples, only one polynomial multiplication is needed, resulting in $O(n \log n)$ operations. As a consequence, the cost of generating public keys is reduced from $O(n^2)$ to $O(n \log n)$ by exploiting the structure of the ring.
