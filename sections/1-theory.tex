\chapter{Theory}

INTRODUCTION

% Give short server-client introduction

\section{Computation theory}
 In this section, it is assumed that the reader has prior knowledge of deterministic- and probabilistic Turing machines as a model of computation (an excellent introduction can be found in \cite{Gol01}). We introduce an alternative model of computation based on sets of circuits for the purpose of protection against stronger adversaries. We include the basics needed to understand cryptography and homomorphic encryption in particular. 

 \subsection*{Digital logic}

\begin{definition}[Circuit]
For $n, m \in \mathbb{N}$ and any field $(\mathbb{F},+,\times)$, an arithmetic circuit is a vector-valued polynomial function $C \colon \mathbb{F}^{n} \to \mathbb{F}^m$. 
\end{definition}

A circuit $C$ is represented by a finite directed acyclic graph with $n$ source nodes (the $n$ inputs) and $m$ sink nodes (the $m$ outputs). The internal nodes of the circuit are called gates. For more details about the structure of a circuit, see \cite{goldreich_2008} or \cite{MF21}. The number of nodes in $C$ is called its \emph{size} and is denoted $|C|$. The longest path in $C$ is called its \emph{depth}.
A circuit is called \emph{Boolean} when the field is $\mathbb{F}_2$ and each gate takes at most 2 inputs. Boolean circuits and arithmetic circuits are equivalent in the sense that the set of functions that can be computed by an arithmetic circuit is equal to the set of functions that can be computed by a Boolean circuit.\footnote{A Boolean circuit is an arithmetic circuit. Conversely, any Boolean circuit can be simulated by converting every gate to XOR and AND gates and using XOR$(a,b) = a+b-2*a*b$, AND$(a,b) = a*b$.} \mbnote{If the input is a string of bits, we assume the circuit is Boolean and if the input is a tuple of arbitrary inputs (messages) in the field, then we assume an arithmetic circuit.}

We consider circuits as algorithms and use them as an alternative approach to the traditional Turing machine model of computation.\footnote{The reason for this alternative model is to assume adversaries are computationally "stronger". See Theorem \ref{thm:compl-class}.} Notice that any given circuit, $C$, can only compute on inputs of the same length whereas a Turing machine $M$ takes inputs of any size $n$. However, a circuit always halts on a given input whereas a Turing machine may not. For the purpose of our discussion relating to cryptography, we assume every Turing machines halts unless otherwise stated. To allow circuits to handle arbitrary length inputs we consider families of circuits.  

\begin{definition}[Circuit family \cite{MF21}]
A circuit family $C = \{C_n\}_{n \in \mathbb{N}}$ is an indexed set of circuits $C_n \colon \mathbb{F}^{n + r} \to \mathbb{F}^m$ where $r,m = \operatorname{poly}(n)$.
\end{definition}

For any input $x$ with length $n$, $C(x) \stackrel{\mathrm{def}}{=} C_n(x)$. For each circuit $C_n \in C$, $r$ represents the random coins used. If $r = 0$ for all $n$ then $C$ is a deterministic circuit family. A circuit family is said to have polynomial-size if there exists a polynomial $p$ such that $|C_n| < p(n)$ for all $n$. 
% \mrnote{
% \begin{definition}[Universal set of gates]
%     Any set of gates that can implement any effectively computable function.
% \end{definition}
% In this paper, we will use the arithmetic gates of multiplication and addition. This is equivalent to the binary gates XOR and AND.
% }

\subsection*{Complexity classes}\label{subsec:Complexity classes}
\begin{definition}[Complexity Class $\operatorname{P}$]
$\operatorname{P}$ is the set of languages $\mathscr{L}$ such that there exists a deterministic polynomial-time Turing machine $M$ satisfying $M(x) = 1 \iff x \in \mathscr{L}$ 
\end{definition}
\begin{definition}[Complexity Class $\operatorname{BPP}$]
$\operatorname{BPP}$ is the set of languages $\mathscr{L}$ such that there exists a probabilistic polynomial-time (PPT) Turing machine $M$ satisfying
\begin{align*}
& \operatorname{Pr}[M(x)=1] \geq 2/3 \text{ if $x \in L$}
\\
& \operatorname{Pr}[M(x)=1] \leq 1/3 \text{ if $x \notin L$}
\end{align*}
\end{definition}
\begin{definition}[Complexity Class $\operatorname{P/poly}$]
$\operatorname{P/poly}$ is the set of languages $\mathscr{L}$ such that there exists a polynomial-size circuit family $C$ satisfying $C(x) = 1 \iff x \in \mathscr{L}$ 
\end{definition}
Informally speaking, circuit families is a stronger model of computation than the PPT Turing machine model in the sense that if there exists a PPT Turing machine for deciding a problem, then there also exists a circuit family that can decide the same problem. The formal statement is as follows: 
\begin{theorem}
    \label{thm:compl-class}
    $\operatorname{P} \subseteq \operatorname{BPP} \subsetneq \operatorname{P/poly}$
\end{theorem}
The first inclusion follows from the fact that if there exists a deterministic Turing machine that decides a language, then that same machine can be seen as a PPT machine that ignores a given input sequence of coin tosses. For the second inclusion, consider a language $\mathscr{L} \in \operatorname{BPP}$ and a corresponding PPT machine $M$ for $\mathscr{L}$. Then, for any given input $x_n$ with length $n$, at least $2/3$ of the set of all possible coin toss sequences are good (good $r$ means $M(x_n;r) = 1 \iff x_n \in \mathscr{L}$). This means that there exists at least 1 sequence of coin tosses that yields the correct result for $2/3$ of the possible inputs of length $n$. \mbnote{By using an alternative (but equivalent) definition} of $\operatorname{BPP}$, it can be shown that there actually exist a coin toss sequence, $r_n$, that yields the correct result for all inputs of length $n$ (see \cite{Adleman1978TwoTO,Gol01} for more detail). Consider circuit $C_n \colon \{0,1\}^{n+|r_n|} \to \{0,1\}$ with $r_n$ hardcoded as inputs where $C_n$ simulates $M$ using $r_n$, i.e., $C_n(x_n) = M(x;r)$. Therefore $C_n(x) = 1 \iff x \in \mathscr{L}$ and $C$ decides $\mathscr{L}$.

Interestingly the first inclusion is speculated to be set equivalence \cite[pp. 126]{Arora}, meaning that a deterministic machine could decide the same languages as a probabilistic one. The second inclusion is proper since every unary language is in $\operatorname{P/poly}$ whereas undecidable ones are not in $\operatorname{BPP}$ (see \cite[pp. 110]{Arora} for details). In this sense, circuit families are a stronger model of computation than PPT Turing machines. We capture this notion with uniformity. 

\begin{definition}[Uniform circuit family]
A circuit family $\{C_n\}_{n \in \mathbb{N}}$ is uniform if there exists a polynomial-time Turing machine $M$ such that $M(1^n)$ outputs the description of $C_n$ for all $n\in \mathbb{N}$.
\end{definition}

A uniform circuit family is polynomial size. The converse is not necessarily true. A family that is not uniform is said to be a non-uniform circuit family. Note that Turing machines are at least as strong as uniform circuit families. More formally, if a uniform circuit family decides $\mathscr{L}$ then there exists a polynomial-time Turing machine that decides $\mathscr{L}$.\footnote{The converse is also true, meaning deterministic polynomial-time Turing machines are exactly as powerful as uniform circuit families. See \cite[pp. 111]{Arora} for details} Simply construct the polynomial-time Turing machine that given any input $x \in \mathscr{L}$, first generates a description of $C_{|x|}$ and then simulates $C_{|x|}(x)$. In other words, the non-uniform circuit families are stronger than the polynomial-time Turing machines.

\section{Probability Theory}
Homomorphic encryption schemes are based on noise. As we will see in Subsection \ref{subsec:LWE}, noise can be sampled from discrete spaces in accordance with a distribution. Since distributions are central in cryptography, it is important they are understood. A distribution is a probability measure on a measurable space $(S, \mathcal{S})$. Typically, probability distributions are associated with random variables; however, in the absence of random variables, distributions are understood as a specified measure function on the given measurable space (See \cite[pp. 83]{kallenberg-probability}).
\begin{definition}[Discrete distribution measure of a random variable]
Consider a probability space $(\Omega, \mathcal{F}, \operatorname{Pr})$ and a discrete measurable space $(S,\mathcal{S})$. Let $X \colon \Omega \mapsto S$ be a random variable. The discrete distribution measure of $X$, or simply \emph{distribution} of $X$, $\chi$ is defined as follows
\begin{equation*}
\begin{aligned}
    \chi \colon \mathcal{S} &\to [0,1]\\
    \{x\} &\mapsto \operatorname{Pr}[X = x]
\end{aligned}
\end{equation*}
We say that $\chi$ is the distribution or \emph{law} of $X$, denoted $\mathcal{L}(X)$. 
\end{definition}
\begin{remark}
    Since $\chi$ is a measure on a discrete space, the description of the singletons are sufficient. More explicitly, $\chi(A) = \sum_{x \in A} \operatorname{Pr}[X = x]$ for $A \in \mathcal{S}$
\end{remark}
A distribution measure for a random variable is a probability measure on the sample space $(S,\mathcal{S})$, as opposed to on the outcome space $(\Omega, \mathcal{F})$. For a given probability space, any random variable $X$ defined on it has a distribution associated with it. We write $x \leftarrow X$ or $x \leftarrow \chi$ for sampling the outcome $x$ from $X$ assuming $\chi$ is its distribution. When $X$ is a space we mean that $x$ is uniformly sampled from $X$.

\begin{definition}[Ensembles] \label{def:prob-ensemble}
    Let $I$ be a countable index set. A \emph{probability ensemble} indexed by $I$ (or just ensemble) is a sequence of random variables $(X_i)_{i \in I}$. A \emph{distribution ensemble} indexed by $I$ is a sequence of distributions $(\chi_i)_{i \in I}$
\end{definition}
In this paper we will exclusively use $\mathbb{N}$ as the index set.
For example, the encryption function is a random variable (PPT algorithm), meaning that a single message $m$ corresponds to many valid ciphertexts. By varying the security parameter of the scheme we construct the probability ensemble $\{Enc(pk,m)\}_{pk \in \mathbb{N}}$
\begin{definition}[Statistical distance] \label{def:statistical-distance}
    Let $S_n$ be finite set for all $n \in \mathbb{N}$ and let $X = (X_n \colon \Omega_n \to S_n)_{n \in \mathbb{N}}$, $Y = (Y_n \colon \Omega_n \to S_n)_{n \in \mathbb{N}}$ be two ensembles. The \emph{statistical distance} is defined as
    \begin{equation*}
        \Delta_{X,Y}(n) \stackrel{\mathrm{def}}{=} \frac{1}{2} \sum_{\alpha \in S_n} |\operatorname{Pr}[X_n = \alpha] - \operatorname{Pr}[Y_n = \alpha]|.
    \end{equation*}
    Let $\chi = \{\chi_n\}_{n \in \mathbb{N}}$, $\psi = \{\psi_n\}_{n \in \mathbb{N}}$ be two discrete distribution ensembles on the same measurable spaces $\{(S_n, \mathcal{S}_n)\}_{n \in \mathbb{N}}$. The statistical distance is defined as
    \begin{equation*}
    \begin{aligned}
        \Delta_{\chi, \psi}(n) \stackrel{\mathrm{def}}{=} \frac{1}{2} \sum_{\alpha \in S_n} |\chi_n(\{\alpha\}) - \psi_n(\{\alpha\})|
    \end{aligned}
    \end{equation*}
\end{definition}
\begin{remark}
    This definition for distribution ensembles assumes every singleton is measurable. A more general definition is $\Delta(\chi, \psi) \stackrel{\mathrm{def}}{=} \sup _{A \in \mathcal{S}}|\chi(A)-\psi(A)|$ 
\end{remark}

\begin{definition}[Negligible function]
    Let $f \colon \mathbb{N} \to [0,1]$. $f$ is negligible if for all positive polynomials $p(\cdot)$, there exists an $N$ such that for all $n>N$, $f(n) < \frac{1}{p(n)}$. We say $f = \operatorname{negl}(n)$.
\end{definition}
\begin{definition}[Perfectly indistinguishable] \label{def:perfectly-indistinguishable}
    Two ensembles (probability or distribution) $X$ and $Y$ are \emph{perfectly indistinguishable} if $\Delta_{X,Y}(n) = 0$ for all $n$.
\end{definition}
\begin{definition}[Statistically indistinguishable] \label{def:statistically-indistinguishable}
    Two ensembles (probability or distribution) $X$ and $Y$ are \emph{statistically indistinguishable} if $\Delta_{X,Y}(n) = \operatorname{negl}(n)$.
\end{definition}
 A desirable property of encryption schemes is to make it unfeasible for adversaries to distinguish encryptions. For two random variables (or distributions) $X$ and $Y$, we want every adversary $C$ to not be able to distinguish samples from $X$ and $Y$. More precisely, an adversary tasked with identifying whether given samples are from $X$ ($C$ outputs 0) or from $Y$ ($C$ outputs 1) should have roughly the same probability of success irrespective of which the samples are generated from. The formal definition is as follows:
\begin{definition}[Computationally indistinguishable \cite{Gol01}] \label{def:computationally-indistinguishable}
    Two ensembles (or distribution ensembles) $X$ and $Y$ are computationally indistinguishable if, for every polynomial-size circuit family $C = \{C_n\}_{n \in \mathbb{N}}$, $$\operatorname{Adv}_{X,Y}(n) \stackrel{\mathrm{def}}{=} |\operatorname{Pr}[C(X_n) = 1] - \operatorname{Pr}[C(Y_n) = 1]| = \operatorname{negl}(n).$$
\end{definition}
$C(X_n), C(Y_n)$ means that the adversary has access to random oracle returning a sample from $X_n$ and $Y_n$ respectively. The point is that, for every adversary $C$ guessing the samples are from one of the random variables or distributions (1 in this case represents from $Y_n$), the probability of being correct is, up to negligible error, equal to the probability of being incorrect. For example, an adversary always guessing 1 has 100\% probability of being incorrect when given samples from $X_n$ and 100\% probability of being correct when given samples from $Y_n$. The intuition is that the advantage in distinguishing the ensembles goes to zero fast (faster than the inverse of all polynomials).

Perfect distinguishability implies statistical indistinguishability as 0 is negligible. Statistical indistinguishability implies computational indistinguishability. To see why, assume $\Delta_{X,Y}(n) = \operatorname{negl}(n)$ and consider any circuit family $C$. Since $X_n$ and $Y_n$ are defined on the same sample space we have
\begin{equation*}
\begin{aligned}
    \operatorname{Adv}_{X,Y}(n) &= |\operatorname{Pr}(X_n) = 1] - \operatorname{Pr}[C(Y_n) = 1]|\\
        &\leq \sum_{\alpha \in S_n} | \operatorname{Pr}[C(X_n = \alpha) = 1 \; | \; X_n = \alpha]\operatorname{Pr}[X_n = \alpha] \\
        &\phantom{=} \qquad - \operatorname{Pr}[C(Y_n = \alpha) = 1 \; | \; Y_n = \alpha]\operatorname{Pr}[Y_n = \alpha] | \\
        &\leq \sum_{\alpha \in S_n} | \operatorname{Pr}[X_n = \alpha] - \operatorname{Pr}[Y_n = \alpha]| = 2\Delta_{X,Y}(n) = \operatorname{negl}(n)
\end{aligned}
\end{equation*}
where the first inequality is due to the triangle inequality and the second is due to conditional probability being upper bounded by 1. Intuitively, there does not exist enough distinguishable outcomes to distinguish the ensembles even if there exists an adversary that always correctly recognize an outcome from $X$ and $Y$ respectively.

\subsection*{Distributions for noise in HE}
To add discrete noise to ciphertexts, it is typical to use the discretized Gaussian distribution introduced by Micciancio and Regev \cite{disc-gauss}. Since this distribution is used so frequently, we give a brief presentation of it here. A continous Gaussian distribution in $\mathbb{R}^n$ centered at $\vec{c}$ where each coordinate is independently sampled from $\mathcal{N}(0, \sigma^2)$, then the multivariate Gaussian distribution is simplified to $\rho_{\vec{c}}(\vec{x})=\frac{1}{\left(2 \pi \sigma^2\right)^{n / 2}} \exp \left(-\frac{1}{2 \sigma^2} \| \vec{x}-\vec{c} \| ^2\right)$. By introducing the scale factor $s \stackrel{\mathrm{def}}{=} \sqrt{2\pi}\sigma$ we get $\rho_{s, \vec{c}}(\vec{x})=\frac{1}{s^n} \exp \left(-\frac{\pi}{s^2} \| \vec{x}-\vec{c} \| ^2\right)$.
The goal is to discretize the gaussian over lattices, see Section \ref{sec:lattices}, by restricting the points to lattice points. For a given lattice $\Lambda \subset \mathbb{R}^n$ we define the normalization constant $\rho_{s, \vec{c}}(\Lambda) \stackrel{\mathrm{def}}{=} \sum_{\vec{x} \in \Lambda} \rho_{s, \vec{c}}(\vec{x})$.
\begin{definition}[Discrete Gaussian distribution]\label{Disc-Gauss}
    Let $\Lambda \subset \mathbb{R}^n$ be a lattice. Then the discrete gaussian distribution is defined as
    \begin{equation*}
        \forall \vec{x} \in \Lambda \colon \quad \textrm{D}_{\Lambda, s, \vec{c}}(\vec{x}) \stackrel{\mathrm{def}}{=} \frac{\rho_{s, \vec{c}}(\vec{x})}{\rho_{s, \vec{c}}(\Lambda)}.
    \end{equation*}            
\end{definition}
\begin{definition}[$\beta$-bounded distribution]
    Let $\chi = \{\chi_n\}_{n\in \mathbb{N}}$ be a distribution ensemble over the integers. $\chi$ is $\beta$-bounded if $x \leftarrow \chi_n \implies \operatorname{Pr}[|x|>\beta] = \operatorname{negl}(n)$
\end{definition}

\section{Cryptographic primitives}
In the following definitions we let the message space be denoted $\mathcal{X}$, the ciphertext space be denoted $\mathcal{Y}$, and the key space be denoted $\mathcal{K} = \mathcal{K}_{pk} \times \mathcal{K}_{sk}$.
\begin{definition}[Encryption scheme]
A correct asymmetric encryption scheme $\mathcal{E} = (\text{KeyGen, Enc, Dec})$ is a triple of algorithms satisfying the following:
\begin{enumerate}[label={$\bullet$}]
    \item KeyGen $\colon \{1\}^* \to \mathcal{K}$ is PPT given by $1^{\lambda} \mapsto (pk,sk)$.
    \item Enc $\colon \mathcal{K}_{pk} \times \mathcal{X} \to \mathcal{Y}$ is PPT given by $(pk,m) \mapsto c$.
    \item Dec $\colon \mathcal{K}_{sk} \times \mathcal{Y} \to \mathcal{X}$ is deterministic and satisfies $(pk, sk) \leftarrow \operatorname{KeyGen}(1^{\lambda}) \implies \operatorname{Dec}(sk, \operatorname{Enc}(pk,m)) = m$.
\end{enumerate}
\end{definition}
\begin{remark}
This paper is only concerned with encryption schemes where decryption always works (correct) and where more than one key is used (asymmetric). Thus, every encryption scheme is assumed to be a correct asymmetric encryption scheme. Furthermore, the decryption algorithm can be considered a PPT algorithm that with probability 1 outputs the correct message for the correct secret key. In other words, the algorithm ignores the input coin toss sequence.
\end{remark}

In this paper, we consider homomorphic encryption (HE) schemes. These schemes include a fourth algorithm, Eval, called the evaluation algorithm which is used by the server calculating on encrypted data.
\begin{definition}[$\mathcal{C}$-homomorphic encryption scheme]
    \label{def:HE-scheme}
An encryption scheme $\mathcal{E}$ is a $\mathcal{C}$-homomorphic encryption scheme for the set of circuits $\mathcal{C}$ if there exists an extra algorithm Eval such that for any $C \in \mathcal{C}$ taking $t$ inputs the following condition holds:
\begin{enumerate}[label={$\bullet$}]
    \item  Eval$ \colon  \mathcal{K}_{pk} \times \mathcal{C} \times \mathcal{Y}^* \to \mathcal{Y}$ is PPT and satisfies $(pk,sk) \leftarrow \operatorname{KeyGen}(1^{\lambda}) \implies \operatorname{Dec}(sk, \operatorname{Eval}(pk, C, \left\langle \operatorname{Enc}(pk, m_1), \dots , \operatorname{Enc}(pk, m_t) \right\rangle)) = C(m_1, \ldots, m_t)$
\end{enumerate}
We say $\mathcal{E}$ can evaluate all circuits in $\mathcal{C}$ and is $\mathcal{C}$-homomorphic.
\end{definition}

The evaluation algorithm runs the ciphertexts through the permissible circuit while also satisfying the requirement that decrypting the resulting ciphertext yields the same result as the plaintexts running through the circuit. To its disposal, the evaluation algorithm is given the public key. The ciphertexts returned by the Eval algorithm are called \emph{evaluated ciphertexts} (suggesting the circuit has evaluated the ciphertexts) and those returned by the encryption algorithm are called \emph{fresh ciphertexts}. Remark that correctness is only guaranteed if the Eval algorithm is given fresh ciphertexts. If the circuit corresponds to the computable function $f$ acting on a vector $c$ of ciphertexts, we denote the evaluated ciphertexts $c_f$ (i.e., $c_f \stackrel{\mathrm{def}}{=} \operatorname{Eval}(pk, f, c)$). Similarly, for the vector $m$ of plaintexts, we denote the evaluated plaintexts $m_f$ (i.e., $m_f \stackrel{\mathrm{def}}{=} f(m)$). Thus, the condition for the Eval algorithm can be written $(pk,sk) \leftarrow \operatorname{KeyGen}(1^{\lambda}) \implies \operatorname{Dec}(sk, c_f) = m_f$.
\begin{figure}
    \input{figures/decryption-homomorphism}
    \caption{The decryption homomorphism. The path through $\mathcal{Y}$ represents computing before decrypting. The path through $\mathcal{X}^t$ represents decrypting before computing.}
    \label{fig:homomorphism}
\end{figure}
In a homomorphic encryption scheme that supports one addition and multiplication of fresh ciphertexts, the decryption function is a ring homomorphism. Consider a valid key pair $(sk,pk)$ which are, for notational simplicity, hard-wired into the decryption and evaluate functions respectively, plaintext ciphertext pairs $(m_1,c_1 = \operatorname{Enc}_{pk}(m_1))$, $(m_2, c_2 = \operatorname{Enc}_{pk}(m_2))$ and circuits $C_+(m_1,m_2) \stackrel{\mathrm{def}}{=} m_1 + m_2$ and $C_{\times}(m_1,m_2) \stackrel{\mathrm{def}}{=} m_1 \times m_2$ that can be evaluated by the scheme. 
\begin{equation*}
\begin{aligned}
\operatorname{Dec}_{sk}(c_1 + c_2) &= \operatorname{Dec}_{sk}(\operatorname{Eval}_{pk}(C_+,\left\langle c_1,c_2 \right \rangle) = C_+(m_1,m_2) = m_1 + m_2 \\
    & = \operatorname{Dec}_{sk}(c_1) + \operatorname{Dec}_{sk}(c_2)\\
\operatorname{Dec}_{sk}(c_1 \times c_2) &= \operatorname{Dec}_{sk}(\operatorname{Eval}_{pk}(C_{\times},\left\langle c_1,c_2 \right \rangle) = C_{\times}(m_1,m_2) = m_1 \times m_2 \\
    & = \operatorname{Dec}_{sk}(c_1) \times \operatorname{Dec}_{sk}(c_2)
\end{aligned}
\end{equation*}
The main idea behind a homomorphic encryption scheme is to give a server encrypted data so that it can compute on that data and return the answer in encrypted form. However, the definition provided allows for trivial homomorphic encryption schemes where the server does nothing. More specifically, consider any set of circuits $\mathcal{C}$ and let $\operatorname{Eval}(pk, C,\left\langle c_1, \dots ,c_t \right\rangle) = (C, \left\langle c_1, \dots, c_t \right \rangle)$. Eval takes a description of a circuit and a tuple of ciphertexts, one for each input wire of the circuit, and simply outputs the description of the circuit together with the given tuple. Clearly, Eval runs in polynomial time. Consider a decryption algorithm that, if given an input of this form, first decrypts the $t$ ciphertexts and then computes $m_f$ using $C$. To ensure that the server actually processes the given inputs we introduce compactness.

\begin{definition}[Compactness]
A $\mathcal{C}$-homomorphic encryption scheme is compact if there exists a polynomial $p(\lambda)$ such that for all $(pk,sk) \leftarrow \operatorname{KeyGen}(1^{\lambda})$, for every $C \in \mathcal{C}$ taking any number $t$ inputs and any $c \in \mathcal{Y}^t$, the size of the output $\operatorname{Eval}(pk, C, \left\langle c_1, \dots, c_t \right\rangle)$ is less than $p(\lambda)$. We say that the scheme compactly evaluates $\mathcal{C}$.
\end{definition}

For a compact $\mathcal{C}$-homomorphic encryption scheme, the size of the output is independent of the circuit function used. In particular, the previous, trivial homomorphic encryption scheme where $\operatorname{Eval}(pk, C,\left\langle c_1, \dots ,c_t \right\rangle) = (C, \left\langle c_1, \dots, c_t \right \rangle)$ is not compact for any set of circuits with unbounded circuit size, which includes circuit families with circuits that do not ignore all except for constantly many inputs, meaning essentially every application of a HE scheme.

\begin{definition}[Fully Homomorphic Encryption (pure FHE)]
Let $\mathcal{C}$ be the class of all circuits. An encryption scheme $\mathcal{E}$ is a fully homomorphic encryption (pure FHE) scheme if it is $\mathcal{C}$-homomorphic and compactly evaluates $\mathcal{C}$.
\end{definition}

For a scheme to be fully homomorphic it is required that it can evaluate circuits of arbitrary size. Many times it suffices to consider only circuits of a beforehand specified depth, $L$, as any deeper circuits are irrelevant to the application. The following definition capture schemes that can evaluate any set of circuits with depths bounded by the client.   

\begin{definition}[Leveled fully homomorphic encryption (leveled FHE)]
An encryption scheme $\mathcal{E}$ with the KeyGen algorithm modified is a leveled fully homomorphic encryption scheme if it satisfies the following:
\begin{enumerate}[label={$\bullet$}]
    \item KeyGen $\colon \{1\}^* \times \{1\}^* \to \mathcal{K}$ is PPT given by $(1^{\lambda},1^L) \mapsto (pk,sk)$.
    \item Let $\mathcal{C}_L$ be the set of circuits with depth less than or equal to $L$. Then $\mathcal{E}$ is $\mathcal{C}_L$-homomorphic.
    \item $\mathcal{E}$ compactly evaluates the set of all circuits. 
\end{enumerate}
\end{definition}
\begin{remark}
    Notice that the length of the evaluated ciphertexts in a leveled FHE scheme is independent of the depth.
    Also note that for any circuit $C$, there exists an $L$ such that a leveled FHE scheme can evaluate it.
\end{remark}

A potential point of contention is the purpose of a pure FHE scheme in the presence of a leveled FHE scheme; why do we not simply choose an $L$ such that the leveled FHE scheme can evaluate any given circuit $C$?

\mrnote{
Possible answer? ask Johan\\
It's not always clear what the depth of the circuit is. Therefore, it may be needed to use an excessively large depth parameter $L$. In a leveled scheme, an increasing $L$ allows for longer keys and ciphertext lengths and consequently a performance overhead. In contrast, a pure FHE scheme is independent of the depth, meaning ciphertexts lengths are only bounded by the security parameter.
}

\subsection*{Security definitions}

In this paper, semantic security refers to security against chosen-plaintext attack (CPA). The definition relates to the following game where the challenger possess the secret key and the player is the adversary trying to break the scheme. Consider encryption scheme $(\text{KeyGen, Enc, Dec, Eval})$ and polynomial-size Boolean circuit family $C = \{C_n\}_{n\in \mathbb{N}}$. The CPA game is defined with the Boolean function $\operatorname{CPA}_{C}(\lambda)$ as follows:
\begin{enumerate}
  \item \textbf{Setup}: Challenger samples $pk \leftarrow \operatorname{KeyGen}(1^{\lambda})$ and sends it to player.
  \item \textbf{Choose}: Player $C$ selects two distinct plaintext messages $(m_0, m_1) \leftarrow C(pk)$ of the same length, and sends them to the challenger.
  \item \textbf{Encrypt}: The challenger randomly picks a bit $b \in \{0, 1\}$ and encrypts the message $m_b$. The encrypted message $c \stackrel{\mathrm{def}}{=} \operatorname{Enc}(pk, m_b)$, called challenge ciphertext, is sent to the player.
  \item \textbf{Guess}: Player $C$ output guess $b' \in \{0,1\}$.
  \item \textbf{Win}: $\operatorname{CPA}_{C}(\lambda) = 
  \begin{cases}
  1 & \text{if } b = b'\\
  0 & \text{if } b \neq b'.
  \end{cases}$
\end{enumerate}

If $\operatorname{CPA}_{C}(\lambda) = 1$ then the adversary $C$ guessed correctly which of their two chosen messages was encrypted, based only on observing the ciphertext. Notice that the game requires the player to choose messages of equal length in the 'choose' phase since the ciphertext length always leaks information about the length of the message, namely an upper bound on the message length.
\begin{definition}[Semantic security (CPA)]
    An encryption scheme is semantically secure if, for all polynomial-size Boolean circuit families $C$, $$| \operatorname{Pr}[\operatorname{CPA}_{C}(\lambda)] - \frac{1}{2} | = \operatorname{negl}(\lambda).$$
\end{definition}
Semantic security means that there exists no algorithm in $\operatorname{P/poly}$ that can do more than negligibly better than guessing randomly in determining the message. Semantic security is equivalent to indistinguishability of encryptions (see \cite{Gol04} for proof).

\begin{definition}[Indistinguishability of encryptions]
    An encryption scheme has indistinguishable encryptions if for any key $(pk,sk) \leftarrow \operatorname{KeyGen}(1^{\lambda})$ and any two distinct messages $m_1, m_2$ of equal length, the ensembles $\{\operatorname{Enc}(pk,m_1)\}_{\lambda \in \mathbb{N}}$ and $\{\operatorname{Enc}(pk,m_2)\}_{\lambda \in \mathbb{N}}$ are computationally indistinguishable.
\end{definition}

Usually, encryption schemes are required to be secure against a stronger type of attack, called chosen-ciphertext attack (CCA). There are two types of CCA attacks; adaptive (called CCA2) and non-adaptive (called CCA1). The CCA1 game is defined exactly like the CPA game but where the player also has oracle access to the decryption algorithm in the choose phase. In other words, the player can decrypt any ciphertext of their choice before submitting the two messages $m_0$ and $m_1$ to the challenger. The CCA2 game is the same as CCA1 except that the player also has oracle access to the decryption algorithm in the guess phase for every ciphertext except the challenge ciphertext. Security against CCA1 and CCA2 attacks are defined analogously to semantic security. Clearly, CCA2 security implies CCA1 security and CCA1 security implies semantic security.

As a consequence of its design, homomorphic encryption schemes cannot be CC2 secure. The reason is that the player can run the evaluate algorithm on the challenge ciphertext with any circuit of choice and then decrypt the evaluated ciphertext. More formally, consider any challenge ciphertext $\operatorname{Enc}(pk,m_b)$ and the identity circuit $C$. \mbnote{Is the identity circuit always in C?}. Player runs $\operatorname{Eval}(pk,C,\operatorname{Enc}(pk,m_b))$, generating a valid evaluated ciphertext of $C(m_b)$. Player then queries decryption and yields $C(m_b) = m_b$. Homomorphic encryption schemes allow the attacker to transform the ciphertext of a message $m$ to a ciphertext to a message related to $m$ by a known function. This property is called \emph{malleability}.

% Circuit privacy here maybe?

One last security definition that will be relevant later is circular security
\begin{definition}[Circular security]
    A semantically secure homomorphic encryption scheme is circular secure if it is semantically secure even when the adversary is given encryptions of the secret key.
\end{definition}
\begin{remark}
    Circular security is not implied by semantic security because an adversary with a random access oracle cannot efficiently query encryptions of the secret key \cite{Bra18-survey}.
\end{remark}

\section{Lattices}\label{sec:lattices}

In this section, we assume every vector is a column vector and we denote a matrix $\textbf{A}$ with boldface. By $\textbf{A} \in \mathbb{F}^{n \times m}$ we mean $\textbf{A}$ is a $n \times m$ matrix with entries in $\mathbb{F}$. Consider a basis $\textbf{B} = \{b_1, \dots, b_k\}$. A lattice with basis $\textbf{B}$ is defined $L(\textbf{B}) \stackrel{\mathrm{def}}{=} \{ \sum_{i=1}^k a_i b_i \; \mid a_i \in \mathbb{Z}\}$. For any integer $q \geq 2$, we define $\mathbb{Z}_q \stackrel{\mathrm{def}}{=} (-\frac{q}{2}, \frac{q}{2}] \cap \mathbb{Z}$. For any tuple of integers $x$ (e.g., integer or matrix), we define $[x]_q$ as the tuple of integers over $\mathbb{Z}_q$ such that each element is congruent mod $q$ to the corresponding element in $x$. For example, $q = 3, x = (5,1,-2,6), [x]_q = (-1,1,1,0)$.

\subsection*{LWE and RLWE}\label{subsec:LWE}
In 2005, Oded Regev introduced \cite{Reg05-LWE} a natural problem; solve a system of modular noisy linear equations. The problem is called learning with errors (LWE) and in 2012, a ring based version called ring-LWE (RLWE) was introduced \cite{RLWE}. Despite being easy to state, the LWE problem turns out to be hard even on average instances. For certain parameter choices, the LWE problem is reducible to extensively studied hard lattice based problems (e.g., GapSVP, SIVP) whereas RLWE is reducible to hard problems on ideal lattices (e.g., ideal-SVP, NTRU). Hardness of these problems are outside the scope of this thesis; we refer the reader to \cite{Reg05-LWE, LWE-classical-reduction, LWE-hardness, RLWE} for more details on hardness results and \cite{Pei16-decade} for a good rundown on hard lattice based problems. Today, essentially all homomorphic encryption schemes are based on LWE and RLWE.

The parameters for $\operatorname{LWE}$ are the integers $n = n(\lambda)$ for the dimension, $q = q(n)$ for the global modulus, $m$ for number of samples and a discrete error distribution measure $\chi = \chi(\lambda)$ over $\mathbb{Z}$.

Consider the space of $n \times m$ matrices $\mathbb{Z}_q^{n \times m}$ with uniform distribution, space of secrets $\mathbb{Z}_q^{n}$ with uniform distribution\footnote{The space of secrets can have distribution $\chi^n$ without loss of hardness. See \cite{Applebaum}.}, space of errors $\mathbb{Z}^{m}$ with discrete distribution $\chi^m$ and the random variable $A_{n, q, \chi, m}$ defined on the direct product as follows
\begin{equation*}
\begin{aligned}
    A_{n, q, \chi, m} \colon \mathbb{Z}_q^{n \times m} \times \mathbb{Z}_q^n \times \mathbb{Z}^m &\to \mathbb{Z}_q^{n \times m} \times \mathbb{Z}_q^m \cong \mathbb{Z}_q^{(n+1) \times m}\\
    (\textbf{A},s,e) &\mapsto (\textbf{A}, b^T \stackrel{\mathrm{def}}{=} [s^T\textbf{A}+e^T]_q) = \left[\begin{array}{c} \textbf{A} \\ b^T \end{array}\right]
\end{aligned}
\end{equation*}
\begin{definition}[LWE distribution]
    The learning with errors distribution is defined as the distribution of $A_{n, q, \chi, m}$
    \begin{equation*}
    \begin{aligned}
        \operatorname{LWE}_{n, q, \chi, m} \stackrel{\mathrm{def}}{=} \mathcal{L}(A_{n, q, \chi, m})
    \end{aligned}
    \end{equation*}
\end{definition}

In words, sample a $n \times m$ matrix $\textbf{A}$ with entries in $\mathbb{Z}_q$ at random, choose a uniformly random secret $s \leftarrow \mathbb{Z}_q^n$ and let $e$ consist of $m$ independent errors from the discrete distribution $\chi$. Calculate $b^T$ (i.e, $[s^T\textbf{A}+e^T]_q$) and output the pair $(\textbf{A},b^T)$. The $\operatorname{LWE}$ distribution specifies the probability of sampling each pair.

There are two versions of the $\operatorname{LWE}$ problem; search-$\operatorname{LWE}$ and decision-$\operatorname{LWE}$.
Informally, take a sample $x \leftarrow \operatorname{LWE}_{n, q, \chi, m}$ and consider the last row. The decision version is to decide whether the last row is a linear combination of the previous $n$ rows or if it is uniformly random and the search version is to find the explicit linear combination assuming it exists.

\begin{definition}[decision-$\operatorname{LWE}$ problem]
    Let $\mathcal{U}_n$ be the uniform distribution on $\mathbb{Z}_q^{(n+1) \times m}$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
        |\operatorname{Pr}[A(\mathcal{U}_n) = 1] - \operatorname{Pr}[A(\operatorname{LWE_{n,q,\chi,m}}) = 1]| > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The decision-LWE hardness assumption is that $\mathcal{U}_n$ and $\operatorname{LWE}_{n,q,\chi,m}$ are computationally indistinguishable (i.e., $\operatorname{LWE}_{n,q,\chi,m}$ is pseudorandom).
\begin{definition}[search-$\operatorname{LWE}$ problem]
    Let $x = (\textbf{A}, b^T) \leftarrow \operatorname{LWE}_{n,q,\chi,m}$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
            \operatorname{Pr}[A(x) = s] > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The search-LWE hardness assumption is that $\operatorname{Pr}[A(x) = s] = \operatorname{negl}(n)$.
There exists a reduction from search-$\operatorname{LWE}$ to decision-$\operatorname{LWE}$ for $q = \operatorname{poly}(n)$, meaning they are equivalently hard \cite{LWE-hardness}.

\subsubsection*{Regev's LWE based cryptosystem}
In the same paper that the $\operatorname{LWE}$ problem was introduced, Regev also described how to construct a simple cryptosystem based on the $\operatorname{LWE}$-assumption. In Regev's cryptosystem, each message is a bit. Given the security parameter $\lambda$, specify the parameters $n(\lambda), q(\lambda), \chi(\lambda), m(\lambda)$ for the system.
\begin{enumerate}
    \item \textbf{Key generation}: Generate a uniformly random $\operatorname{LWE}$ secret $s' = (s_1, \dots, s_n) \leftarrow \mathbb{Z}_q^n$ and let $s = (s_1, \dots, s_n, -1) \in \mathbb{Z}_q^{n+1}$. Using $s'$, generate the $(n+1) \times m$ matrix $\textbf{A}' \stackrel{\mathrm{def}}{=} (\textbf{A}, b^T) \leftarrow \operatorname{LWE}_{n,q,\chi,m}$. Let $\text{KeyGen}(\lambda)$ return $\textbf{A}' \in \mathbb{Z}_q^{(n+1)\times m}$ as the public key and $s \in \mathbb{Z}_q^{n+1}$ as the secret key.
    \item \textbf{Encryption}: Generate a random 'subset' vector $r \leftarrow \{0,1\}^m$. To encrypt a bit $m$, compute $c = \text{Enc}(\textbf{A'},m) \stackrel{\mathrm{def}}{=} [b \cdot \lfloor q/2 \rfloor \cdot (0, \dots, 0, -1) + \textbf{A}'r]_q \in \mathbb{Z}_q^{n+1}$.
    \item \textbf{Decryption}: To decrypt, compute $z \stackrel{\mathrm{def}}{=} [\left \langle s, c \right \rangle]_q$ and let $\text{Dec}(s,c)$ be $0$ if $|z| < q/4$ and $1$ otherwise.
\end{enumerate}

Correctness:

Security:

Homomorphic properties:

Not bootstrappable:

\subsection*{RLWE}
The LWE problem is conceptually easy to understand but suffers from expensive overhead. Each element in $b$ is a perturbed linear combination of the secret $s$ and the corresponsing column in $\textbf{A}$, resulting in $O(n)$ operations. To get $m = n$ samples, the total number of operations is $O(n^2)$. In 2012, a more compact ring based learning with errors problem ($\operatorname{RLWE}$) was introduced by Lyubashevsky, Peikert and Regev in \cite{RLWE}.

The parameters for $\operatorname{RLWE}$ are the integers $n = n(\lambda)$ for the dimension, $q = q(n)$ for the global modulus and a discrete error distribution measure $\chi = \chi(\lambda)$ over $\mathbb{Z}$.

Let the dimension $n = 2^k$ for some natural number $k$ and consider the irreducible polynomial $f(x) = x^n + 1$. Define the polynomial ring $R_q \stackrel{\mathrm{def}}{=} \mathbb{Z}_q[x] /\langle f(x)\rangle$. The ring $R_q$ is viewed as the ring of polynomials with coefficients in $\mathbb{Z}_q$, having degree less than $n$. There is a natural correspondence between elements of $R_q$ and $\mathbb{Z}_q^n$ where each coefficient corresponds to an element in the vector. Let the error space $R_q'$ be $R_q$ endowed with error distribution $\chi^n$ over the integer coefficients and consider the random variable $A'_{n, q, \chi}$ defined as follows
\begin{equation*}
\begin{aligned}
    A'_{n, q, \chi} \colon R_q \times R_q' \times \mathbb{Z}^n &\to R_q^2\\
    (a,s,e) &\mapsto (a, b \stackrel{\mathrm{def}}{=} [a \cdot s + e]_q)
\end{aligned}
\end{equation*}
\begin{definition}[RLWE distribution]
    The learning with errors distribution is defined as the distribution of $A'_{n, q, \chi}$
    \begin{equation*}
    \begin{aligned}
        \operatorname{RLWE}_{n, q, \chi} \stackrel{\mathrm{def}}{=} \mathcal{L}(A'_{n, q, \chi})
    \end{aligned}
    \end{equation*}
\end{definition}
In words, sample a uniformly random polynomial $a \in R_q$, a uniformly random secret $s \in R_q$ and a random error $e \in R_q$ from the discrete distribution $\chi^n$. Calculate $b$ (i.e, $[a \cdot s + e]_q$) and output the pair $(a,b)$. The $\operatorname{RLWE}$ distribution specifies the probability of sampling each pair.

The decision-$\operatorname{RLWE}$ problem is to distinguish between the $\operatorname{RLWE}$ distribution and the uniform distribution on $R_q^2$ and the search problem is to find the secret $s$ given a sample $(a,b) \leftarrow \operatorname{RLWE}_{n,q,\chi}$.
\begin{definition}[decision-$\operatorname{RLWE}$ problem]
    Let $\mathcal{U}_n$ be the uniform distribution on $R_q^2$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
        |\operatorname{Pr}[A(\mathcal{U}_n) = 1] - \operatorname{Pr}[A(\operatorname{RLWE_{n,q,\chi}}) = 1]| > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The decision-$\operatorname{RLWE}$ hardness assumption is that $\mathcal{U}_n$ and $\operatorname{RLWE}_{n,q,\chi}$ are computationally indistinguishable (i.e., $\operatorname{RLWE}_{n,q,\chi}$ is pseudorandom).
\begin{definition}[search-$\operatorname{RLWE}$ problem]
    Let $x = (a, b) \leftarrow \operatorname{RLWE}_{n,q,\chi}$. Construct a PPT algorithm $A$ such that 
    \begin{equation*}
        \begin{aligned}
            \operatorname{Pr}[A(x) = s] > \operatorname{negl}(n)
        \end{aligned}
    \end{equation*}
\end{definition}
The search-$\operatorname{RLWE}$ hardness assumption is that $\operatorname{Pr}[A(x) = s] = \operatorname{negl}(n)$.

Note that in $\operatorname{LWE}$, the sample size $m$ is embedded as a parameter while in $\operatorname{RLWE}$, adversary generates $m = \operatorname{poly}(\lambda)$ samples from the $\operatorname{RLWE}_{n,q,\chi}$ themselves.



The main issue with basing schemes of the LWE problem is the inneficient key sizes. The key size is at least quadratic(why?) in the dimension $n$ and hence the security parameter $\lambda$. The ring learning with errors problem (RLWE) was introduced by Lyubashevsky, Peikert and Regev in \cite{RLWE} to address this issue. The RLWE problem is defined over a polynomial ring $\mathbb{Z}_q[x]/(x^n+1)$ and the secret is a polynomial $s \in \mathbb{Z}_q[x]/(x^n+1)$ with coefficients from $\mathbb{Z}_q$. The error is a polynomial $e \in \mathbb{Z}_q[x]/(x^n+1)$ with coefficients from a discrete distribution $\chi$. The RLWE distribution is defined as the distribution of the pair $(a, as+e)$ where $a$ is a uniformly random polynomial in $\mathbb{Z}_q[x]/(x^n+1)$.
- LWE is inneficient. 

\section{History of fully homomorphic encryption}
Began with rivest, adleman and Dertouzos in 1978 and the paper about Data Banks. 
They identified the use of delegating computation to a third party.

To perform homomorphic evaluation on arbitrary functions, a scheme needs to support unlimited number of multiplication and addition of ciphertexts. The problem was thus to find a scheme that both secure and also supports homomorphic addition and multiplication.

RSA supports multitplication,

Paillier supports addition.

\subsection*{First generation}
Gentry scheme is based on ideal lattices. The construction considers a polynomial ring over the integers modulo an ideal generated by a cyclotomic polynomial. Then there exists an ideal with norm polynomially bounded with respect to the dimension such that the ideal generates a lattice (see \cite{Gentry-Thesis} for details). The security of Gentry's scheme was based on three hardness assumptions: sparse subset sum problem (SSSP), bounded-distance decoding problem (BDD) and the ideal shortest vector problem (ideal-SVP). The original decryption function in Gentry's scheme was not bootstrappable. He used a method called squashing to make it so. The idea was to include extra information in the public key which allowed for easier decryption but also introduced the SSSP hardness asumption.

The Gentry's scheme was improved by Smart and Vercauteren in \cite{SV09-batch} where they introduced batching of multiple plaintexts encrypted into a single ciphertext using the Chinese Remainder Theorem (ciphertext packing is the same idea where multiple ciphertexts are packed together). Gentry and Halevi implemented the scheme in \cite{GS10-impl}, including the use of the batching technique and an optimized squashing technique to bring down the degree of the decryption polynomial from hundreds (estimated by Smart and Vercauteren) to 15. In Gentry's original scheme, the key generation algorithm was impractically slow. In their implementation, they reduced the asymptotic complexity to $\tilde{O}\left(n^{1.5}\right)$ for cyclotomic fields where the root of unity is a power of 2. Scholl and Smart extended the implementation to arbitrary cyclotomic fields in \cite{SS11-keygen}.

In 2010, Marten van Dijk, Craig Gentry, Shai Halevi, and Vinod Vaikuntanathan finalized a new scheme (DGHV scheme) that was based on multiplication and addition over the integers as opposed to over polynomial rings \cite{DGHV10}. The hardness of the DGHV scheme was based on the approximate greatest common divisor problem (AGCD), and the SSSP due to squashing of the decryption circuit. Subsequent works optimised the DGHV scheme through modulus switching in \cite{DGHV-modswitch} and plaintext batching in \cite{DGHV-batch1} and \cite{DGHV-batch2}.

\subsection*{Second generation}
The second generation began in 2011 with Brakerski and Vaikuntanathan \cite{BV11}. Their paper introduced two main contributions. Their first contribution was to base the hardness of the proposed BV scheme on the well known LWE problem, which means using arbitrary lattices instead of ideal lattices. Their second contribution was the removal of squashing from previous schemes (Gentry and Halevi, independently, also managed to remove squashing in \cite{Gen-Hal-no-squash}). This meant that the BV scheme did not require the SSSP hardness assumption. As an optimization technique, the paper was the first to introduce what would later be called modulus switching. A downside of the BV scheme (and the rest of the schemes based on LWE in the second generation) was that an expensive step called re-linearization is nessesary to prevent homomorphic multiplication causing ciphertext length from growing exponentially. In the BV scheme, homomorphic multiplication corresponds to a tensor product, changing the structure of the ciphertext. In order to re-linearize the result, the scheme uses key-switching. This requires applying a large re-linearization matrix of size $\Omega(n^3)$ (embedded in the public key) to the tensorproduct.

In a follow up paper in 2011, Brakerski, Gentry and Vaikuntanathan introduced the BGV scheme that showed, for the first time, bootstrapping was not nessesary for a fully homomorphic encryption scheme. Their construction worked for both LWE and RLWE, and ironically used bootstrapping as an optimization technique. Brakerski later modified the LWE based BGV scheme by replacing the modulus switching technique with a scale invariant approach \cite{Bra12-BFV} \mbnote{explain what he did}. Fan and Vercauteren converted Brakerski's scale invariant scheme to the RLWE setting, resulting in the BFV scheme \cite{FV12-BFV}. As a part of the second generation of homomorphic encryption, there were schemes based on the NTRU public key encryption scheme from 1998 \cite{NTRU}. However, these schemes required parameter sizes larger than originally proposed due to vulnerabilities from subfield lattice attacks \cite{NTRU-attack}.

\subsection*{Third generation}
In 2013, Gentry, Sahai and Waters introduced a new scheme called the GSW scheme \cite{GSW13}. The GSW scheme was also based on LWE, but unlike its predessors, it did not require the re-linearization step. This is because the scheme operates on matrices which has an inherent natural addition and multiplication operation. Since the relinearization matrix is no longer needed, the space complexity of GSW is quasi-quadratic as opposed to quasi-cubic for BGV and BFV. Furthermore, GSW also did not require bootstrapping to achieve FHE. A downside of the GSW scheme is the complexity of ciphertext matrix multiplication, yielding in slower multiplication that the ring based second generation schemes.

A defining trait of the third generation is the efficiency gain from bootstrapping. There were two main new faster bootstrapping algorithms. Jacob Alperin-Sheriff and Chris Peikert \cite{A-S-P-boot} introduced bootstrapping of non-packed ciphertexts in quasilinear time w.r.t the security parameter (which is important in the third generation as there is no packing) and Gama et al. \cite{Gama-boot} built on their work and introduced a new type of homomorphic gate. Léo Ducas and Daniele Micciancio developed a scheme called FHEW that used Alperin-Sheriff and Peikerts bootstrapping algorithm to allow for much faster bootstrapping using what is now called programmable bootstrapping \cite{FHEW}. Another paper introuced a scheme based on the LWE over the torus, meaning a stricter security assumption, called TFHE \cite{TFHE} which allowed for bootstrapping in 0.1 milliseconds after subsequent optimizations \cite{MP-fhew-tfhe}.

\subsection*{Fourth generation}
The fourth generation of homomorphic encryption schemes began in 2016 when Jung Hee Cheon, Andrey Kim, Miran Kim and Yongsoo Song introduced a new RLWE based leveled FHE scheme called CKKS \cite{CKKS16} which they subsequently turned into a pure FHE scheme through bootstrapping in \cite{CKKS-boot}. CKKS is based on approximate arithmetic, allowing for computation on real and complex numbers. To achieve this, a vector of numbers (real or complex) are encoded using rounding as a integral plaintext polynomial in a cyclotomic polynomial ring. This is a fundamentally different approach as the scheme operates on an approximation of the message as opposed to the real message. The CKKS scheme is useful for applications concerning floating point numbers, such as machine learning and neural networks. Subsequent works focused on optimizing the bootstrapping and ciphertext packing techniques.

In 2020, Baiyu Li and Daniele Micciancio showed that the CKKS scheme was vulnerable to passive attacks with respect to IND-CPA security \cite{CKKS-attack}. To mitigate this issue, a new security notion called IND-CPA+ was introduced. IND-CPA+ and IND-CCA1 differ in that the adversary is only allowed to query decryption on evaluated ciphertexts, as opposed to arbitrary ciphertexts. Li and Micciancio showed that IND-CPA+ is eequivalent to IND-CPA for exact encryption schemes but strictly stronger for approximate schemes like CKKS. 

\section{Noise management}

The main problem with homomorphic encryption schemes is the noise. Noise is introduced in the ciphertexts during the encryption process and when the ciphertexts undergo homomorphic operations, the noise grows. After sufficiently many operations, the noise grows to the point where the decryption of the evaluated ciphertext fails. In order to reach FHE, it is necessary to control the noise to allow for sufficient number of operations. Noise management is the process of controlling the noise during homomorphic evaluation. In his 2009 seminal PHD thesis \cite{Gentry-Thesis}, Craig Gentry showed that FHE was possible by using a noise management technique called Bootstrapping. Bootstrapping is an algorithm that transforms a possibly noisy ciphertext into a correct evaluated ciphertext with little noise by using an encryption of the secret key to decrypt the noisy ciphertext homomorphically.

\subsection*{Evaluated ciphertexts vs fresh ciphertexts}
Recall that in Definition \ref{def:HE-scheme}, the decryption of an evaluated ciphertext is only required to be correct if the ciphertext is a fresh ciphertext. \mbnote{Explain Why we care}. The question is then if it is possible to pass evaluated ciphertext to the Eval algorithm instead of fresh ones.

A HE scheme is said to be $i$-hop if the Eval algorithm can be called on its own output up to $i$ times. A HE scheme that satisfies the definition is $0$-hop, also called \emph{single-hop}, and multi-hop if it is $i$-hop for all $i$. 

\subsection*{Note on hard-wiring ciphertexts in circuits}
Not nessesary. Gentry did not hardwire, and instead he encrypted messages twice, passed the double encrypted message as inout where the inner layer was decrypted homomorphically.
In practice, the server sees the ciphertext and constructs the dec function for that ciphertext specifically, designed to only take the secret key as input.

\subsection*{Key-Switching}
This section is based on \cite{Bra18-survey}.

As a natural segway into bootstrapping, we first introduce a related but different concept called key-switching. Since HE schemes are designed with the constraint of supporting homomorphic operations, they are often inefficient. Therefore, it would be desirable to use a more efficient non-homomorphic scheme to encrypt the large messages, but still retaining the homomorphic property. Key-switching is a technique that allows for homomorphic computation on ciphertexts encrypted under a non-homomorphic scheme. In particular, it allows for transforming a ciphertext under a non-HE scheme to a corresponding ciphertext under a HE scheme. The idea is to encrypt the much shorter secret key of the non-HE scheme under the public key of the HE scheme and hard-wire the ciphertexts into the function of interest.

Let $(\text{H.KeyGen, H.Enc, H.Dec, Eval})$ be a homomorphic encryption scheme and $(\text{KeyGen, Enc, Dec})$ be a non-homomorphic encryption scheme. Let $(hpk,hsk) \leftarrow \operatorname{H.KeyGen}(\lambda)$ and $(pk,sk) \leftarrow \operatorname{KeyGen}(\lambda)$. Consider computable function $C$, the vector of ciphertexts $c \leftarrow \operatorname{Enc}(pk,m)$ and an encrypted secret key $sk' \leftarrow \operatorname{H.Enc}(hpk,sk)$. Define $\hat{C}_c(\cdot) \stackrel{\mathrm{def}}{=} C(\operatorname{Dec}(\cdot, c))$. $C(m)$ can be computed homomorphically by decrypting $\operatorname{Eval}(hpk,\hat{C}_c, sk')$. Indeed, this is a correct encryption of $C(m)$ since
\begin{equation*}
    \begin{aligned}
        \operatorname{Dec}(hsk,\operatorname{Eval}(hpk,\hat{C}_c, sk')) = \hat{C}_c(sk) = C(\operatorname{Dec}(sk, c)) = C(m)
    \end{aligned}
\end{equation*}
We have shown that it is possible to use a non-homomorphic encryption scheme to encrypt the message and still perform homomorphic computation on it. Key-switching transforms a ciphertext encrypted under a non-HE scheme to an evaluated ciphertext encrypted under a HE scheme.

The underlying assumption is that the HE scheme can evaluate $\hat{C}_c$, meaning it can first run the decryption algorithm and then compute the desired function $C$ to generate a valid evaluated ciphertext. Even under the assumption that the decryption algorithm is simple enough to be evaluated by the scheme, a general $C$ consists of several multiplication and addition gates, meaning it is unlikely that the scheme can evaluate $\hat{C}_c$. However, if it is possible to split $C$ into smaller components, $C = C^m \circ \dots \circ C^1$, and evaluate each component separately, $c_i = \operatorname{Eval}(hpk,\hat{C}^i_{c_{i-1}}, sk')$, where $c_0 \leftarrow Enc(pk,m)$, computing $C$ homomorphically is achievable assuming $\hat{C}^i_{c_{i-1}}$ is permissible for all $i$. However, as the construction currently stands, further computation on the ciphertext is not possible. To see why, consider $c_1 = \operatorname{Eval}(hpk,\hat{C}^1_{c_0}, sk')$ and let $c_2 = \operatorname{Eval}(hpk,\hat{C}^2_{c_1}, sk')$. We hope decrypting $c_2$ yields $(C^2 \circ C^1)(m)$, but $\operatorname{Dec}(hsk,c_2) = \operatorname{Dec}(hsk,\operatorname{Eval}(hpk,\hat{C}^2_{c_1}, sk')) = C^2(\operatorname{Dec}(sk, c_1))$. However, since $c_1$ is encrypted under the HE scheme, the non-homomorphic decryption algorithm applied to $c_1$ does not make sense and decryption fails.

\subsection*{Bootstrapping}
Key-switching is a nice optimization technique for encrypting messages faster, but it does not allow for further computation on the ciphertext. The requirement is that the decryption algorithm and the secret key originate from the HE scheme. We therefore only consider the HE scheme. Let $(\text{KeyGen, Enc, Dec, Eval})$ be a HE scheme, $(pk, sk) \leftarrow \operatorname{KeyGen}(\lambda)$ and $sk' \leftarrow \operatorname{Enc}(pk, sk)$. Since this construction encrypts the secret key using its own public key, circular security is assumed (this assumption is discussed further below). Under this construction, decryption of $c_1$ is still correct as $\operatorname{Dec}(sk, c_1) = C^1_{c_0}(sk) = C^1(\operatorname{Dec}(sk,c_0)) = C^1(m)$, but the difference is that decryption of $c_i$ also works since, by induction,
\begin{equation*}
    \begin{aligned}
        \operatorname{Dec}(hsk,\operatorname{Eval}(hpk,\hat{C}^i_{c_{i-1}}, sk')) = \hat{C}^i_{c_{i-1}}(sk) = C^i(\operatorname{Dec}(sk, c_{i-1})) = C^i \circ C^{i-1} \circ  \dots \circ C^1(m)
    \end{aligned}
\end{equation*}
In essence, we have constructed a method to evaluate $C$ as follows: The first step is to evaluate a component of $C$ on the encryption of the secret key to obtain an evaluated ciphertext. The second step is to generate a circuit which is the composition of the decryption circuit for the previous evaluated ciphertext and the consecutive component of $C$. The third step is to evaluate the generated circuit on the same ciphertext, namely the encryption of the secret key. Repeating this process ultimately yields $c_m$ which decrypts to $C(m)$. Since each evaluated ciphertext $c_1, \dots, c_m$ is an evaluation of a fresh ciphertext, $sk'$, the decryption is guaranteed to work. 

Splitting the desired function $C$ into multiple components $C^1, \dots, C^m$ is the key insight into constructing FHE. Consider the simplest case; each component function is either one multiplication gate or one addition gate. In other words, for a vector of ciphertexts $c = \left\langle c_1, c_2 \right\rangle$, define a multiplicative component circuit of $C$ as $C^i(c) = c_1 \times c_2$, $\hat{C}^i_c(\cdot) = C^i(\operatorname{Dec}(\cdot, c)) = C^i(\left\langle \operatorname{Dec}(\cdot, c_1), \operatorname{Dec}(\cdot, c_2) \right\rangle) = \operatorname{Dec}(\cdot, c_1) \times \operatorname{Dec}(\cdot, c_2)$ and where the addition case is analogous. Note that $\hat{C}^i_c(sk) = m_1 \times m_2$. It turns out that if the scheme can evaluate just these two types of circuits, then it can evaluate every circuit. This is the idea behind bootstrapping.
\begin{definition}[Bootstrappable encryption scheme]
    Let $\mathcal{E}$ be a $\mathcal{C}$-homomorphic encryption scheme. Consider the following \emph{augmented decryption circuits} for $\mathcal{E}$:
    \begin{equation*}
    \begin{aligned}        
        B_{c_1,c_2}^{(m)}(\cdot) \stackrel{\mathrm{def}}{=} \operatorname{Dec}(\cdot, c_1) \times \operatorname{Dec}(\cdot, c_2)\\
        B_{c_1,c_2}^{(a)}(\cdot) \stackrel{\mathrm{def}}{=} \operatorname{Dec}(\cdot, c_1) + \operatorname{Dec}(\cdot, c_2)
    \end{aligned}
    \end{equation*}
    $\mathcal{E}$ is \emph{bootstrappable} if
    \begin{equation*}
    \{B_{c_1,c_2}^{(m)}(\cdot), B_{c_1,c_2}^{(a)}(\cdot) \; \mid \; c_1, c_2 \in \mathcal{Y}\} \subset \mathcal{C}
    \end{equation*}
\end{definition}
The augmented decryption circuits have the ciphertexts hard-wired into its description and takes as input an encryption of the secret key. A bootstrappable scheme correctly evaluates the set of all augmented decryption circuits. In particular, it correctly evaluates its own decryption circuit by letting $c_2$ be an encryption of the multiplicative or additive identity respectively.
\begin{theorem}[Gentrys bootstrapping theorem, simplified by Vaikuntanathan \cite{Gentry-Thesis, Vai-survey}]
Any bootstrappable scheme is leveled-FHE. Furthermore, if circular security holds, it is pure FHE.
\end{theorem}
\begin{remark}
    Bootstrapping is sufficient for leveled-FHE, but not necessary. See \cite{BGV12-no-bootstrap} for a leveled-FHE scheme that does not require bootstrapping.
\end{remark}
\begin{proof}
    test
\end{proof}
We first introduce notation and then explain bootstrapping further. Let $m'$ denote encrypted message $m$ and $sk'$ denote encrypted secret key $sk$. If a scheme assumes circular security, then one valid key pair $(pk,sk)$ is sufficient for arbitrarily many subroutine calls where every encryption is made using $pk$. However, if circular security is not assumed, every bootstrapping subroutine call requires a new valid key pair. Consider a sequence of independently sampled valid key pairs $\{(pk_i,sk_i)\}_{i = 0, 1, \dots}$. Let $m^{(k)}$ and $sk_i^{(k)}$ denote valid encryptions under public key $pk_k$, meaning $\operatorname{Dec}(sk_k,m^{(k)}) = m$ and $\operatorname{Dec}(sk_k,sk_i^{(k)}) = sk_i$. The first bootstrapping subroutine call is done using $i = 0$. In the bootstrapping algorithm we set $k = i+1$ so that the encryption of every secret key made under the next public key, meaning the circular security assumption is avoided. 

\mbnote{Showing how a bootstrapping subroutine works}

Consider a circular secure bootstrappable homomorphic encryption scheme $\mathcal{E}$ and assume we need the homomorphic multiplication\footnote{The case for addition of ciphertexts works the exact same way. We focus on multiplication here since addition usually only increases the noise slightly.} of two ciphertexts $m_1', m_2'$ encrypted under $pk$, but that the noise of the resulting evaluated ciphertext would cause decryption to fail. Consider instead the less noisy ciphertext $m_{1,2}' \stackrel{\mathrm{def}}{=} B_{m_1',m_2'}^{(m)}(sk')$. In other words, encrypt the secret key and pass it as input to the circuit.

Indeed, $m_{1,2}'$ is a valid ciphertext of $m_1 \times m_2$ since 
\begin{equation*}
    \begin{aligned}
        \operatorname{Dec}(sk, m_{1,2}') &= \operatorname{Dec}(sk, B_{m_1',m_2'}^{(m)}(sk'))\\
        &= B_{m_1',m_2'}^{(m)}(sk) \\
        &= \operatorname{Dec}(sk, m_1') \times \operatorname{Dec}(sk, m_2')\\
        &= m_1 \times m_2
    \end{aligned}
\end{equation*}
If circular security is not assumed, the process becomes more complicated. For bootstrapping round $i$, where $i = 0$ represents the first round, let $m_{1,2}^{(i+1)} \stackrel{\mathrm{def}}{=} B_{m_1^{(i)},m_2^{(i)}}^{(m)}(sk_i^{(i+1)})$. Correctness follows from
\begin{equation*}
    \begin{aligned}
        \operatorname{Dec}(sk_{i+1}, m_{1,2}^{(i+1)}) &= \operatorname{Dec}(sk_{i+1}, B_{m_1^{(i)},m_2^{(i)}}^{(m)}(sk_i^{(i+1)})) \\
        &= B_{m_1^{(i)},m_2^{(i)}}^{(m)}(sk_i)\\
        &= \operatorname{Dec}(sk_i, m_1^{(i)}) \times \operatorname{Dec}(sk_i, m_2^{(i)})\\
        &= m_1 \times m_2
    \end{aligned}
\end{equation*}
Note that both $m_{1,2}'$ and $m_1' \times m_2'$ decrypts to $m_1 \times m_2$. The idea behind bootstrapping is that $m_{1,2}'$ has less noise.

\mbnote{In practice, we don't use augmented decryption circuits but instead we just refresh the ciphertext. In this case, we only need the dec func to be permitted.}
